# NLP Project â€” Story Summarization, Question Answering, and Character Trait Extraction

## ğŸ“š Overview

This project implements an NLP system **built from scratch** (without using any pre-trained language models or LLMs). The system is designed to perform three key tasks on narrative stories:

1. **Story Summarization** â€” Generate concise summaries of long narrative stories.
2. **Question Answering (QA)** â€” Answer questions based on the story context.
3. **Character and Trait Extraction** â€” Identify main characters and extract their traits or descriptive attributes.

---

## ğŸ—ï¸ Project Structure

Project/
â”‚
â”œâ”€â”€ Src/
â”‚ â”œâ”€â”€ train.py # Summarization model training
â”‚ â”œâ”€â”€ train_qa.py # QA model training
â”‚ â”œâ”€â”€ summarize.py # Generate summaries by using the model
â”‚ â”œâ”€â”€ qa_generate.py # Generate QA predictions by using the model
| |
â”‚ â”œâ”€â”€ character_extract.py # Character trait extraction
| |
â”‚ â”œâ”€â”€ Utils/
â”‚ â”œâ”€â”€ vocab.py # Vocabulary utilities
â”‚ â””â”€â”€ vocab_qa.py # Separate vocab for QA
| |
â”‚ â”œâ”€â”€ models/
â”‚ â””â”€â”€ summarizer.py # Seq2Seq model with attention
â”‚ |
â”œâ”€â”€ Data/
â”‚ â”œâ”€â”€ small_narrativeqa.json # Processed data for summarization
â”‚ â”œâ”€â”€ train_narrativeqa_qa.json # Processed data for QA
â”‚ â”œâ”€â”€ vocab.json # Saved vocab for summarization
â”‚ â”œâ”€â”€ vocab_qa.json # Saved vocab for QA
â”‚ â”œâ”€â”€ model_weights.pth # Saved summarization model weights
â”‚ â””â”€â”€ model_weights_qa.pth # Saved QA model weights
â”‚
â””â”€â”€ README.md # This file


------------Training------------------
Summarization
    python Src/train.py

Question Answering
    python Src/train_qa.py



------Generating outputs--------------
Generate summaries
    python Src/summarize.py

Generate QA predictions
    python Src/qa_generate.py

Extract characters and traits
    python Src/character_extract.py


Design Highlights
--No pre-trained models used â€”  models were trained from scratch on NarrativeQA subsets.
--Separate vocabularies for summarization and QA tasks to ensure independence.
--Seq2Seq with attention architecture for both summarization and QA, enabling the model to focus on relevant parts of long contexts.